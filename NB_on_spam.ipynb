{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svetaepc/ds_py/blob/master/NB_on_spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer\n",
        " "
      ],
      "metadata": {
        "id": "zHIf5kWz6tAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.ru/6-2-feature-extraction/"
      ],
      "metadata": {
        "id": "EJ2NDeAv67RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer реализует как токенизацию, так и подсчет вхождений в одном классе"
      ],
      "metadata": {
        "id": "tbE8O2WS6-Pa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0D_qsS3BMF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        " \n",
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте использовать его для токенизации и подсчета вхождений слов в минималистичном корпусе текстовых документов.  \n",
        "Каждому члену, найденному анализатором во время подбора, присваивается уникальный целочисленный индекс, соответствующий столбцу в результирующей матрице.\n"
      ],
      "metadata": {
        "id": "9HTjfqc57PBA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rTtCEOdAR_i",
        "outputId": "abbb1ae6-0528-4403-b0f2-3212c53ed996"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Конфигурация по умолчанию токенизирует строку, извлекая слова не менее чем из 2 букв. Конкретную функцию, выполняющую этот шаг, можно запросить явно:"
      ],
      "metadata": {
        "id": "xP00dxlx7vu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "analyze(\"This is a text document to analyze.\") == (\n",
        "     ['this', 'is', 'text', 'document', 'to', 'analyze'])"
      ],
      "metadata": {
        "id": "C1ameSV27vOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae20bb25-10a6-40f5-baab-b3ffb3dd7b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что в предыдущем корпусе первый и последний документы содержат одни и те же слова, поэтому они закодированы в равных векторах. В частности, мы теряем информацию о том, что последний документ является вопросительной формой. Чтобы сохранить некоторую локальную информацию о порядке, мы можем извлечь биграмма или триграммы слов в дополнение к 1 грамму (отдельные слова):"
      ],
      "metadata": {
        "id": "AIyE-foL8USJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDU9-RjF2sFa",
        "outputId": "b8f3e7bb-0457-42fa-9e14-fd18b8934a2a"
      },
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "print(vectorizer2.get_feature_names_out())\n",
        "print(X2.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'and this' 'and this is' 'document' 'document is' 'document is the'\n",
            " 'first' 'first document' 'is' 'is the' 'is the first' 'is the second'\n",
            " 'is the third' 'is this' 'is this the' 'one' 'second' 'second document'\n",
            " 'the' 'the first' 'the first document' 'the second' 'the second document'\n",
            " 'the third' 'the third one' 'third' 'third one' 'this' 'this document'\n",
            " 'this document is' 'this is' 'this is the' 'this the' 'this the first']\n",
            "[[0 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
            " [0 0 0 2 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0]\n",
            " [1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0]\n",
            " [0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOHyRQICJcUy"
      },
      "source": [
        "## TFIDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В большом текстовом корпусе некоторые слова будут присутствовать очень часто (например, «the», «a», «is» на английском языке), следовательно, несут очень мало значимой информации о фактическом содержании документа. Если бы мы передавали данные прямого подсчета непосредственно классификатору, эти очень частые термины затеняли бы частоты более редких, но более интересных терминов.\n",
        "\n",
        "Чтобы повторно взвесить функции счетчика в значения с плавающей запятой, подходящие для использования классификатором, очень часто используется преобразование tf – idf."
      ],
      "metadata": {
        "id": "tRL6ty139zzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf означает частоту термина, а tf – idf означает частоту термина, умноженную на обратную частоту документа:"
      ],
      "metadata": {
        "id": "oeQJKHa499Jg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9fbd8sfA5GL"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DFk3nxh2tNT",
        "outputId": "127c55c6-3df4-4040-b303-b7c11ae2a8f5"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wxvR84QJVRS"
      },
      "source": [
        "##word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В реальных приложениях модели Word2Vec создаются с использованием миллиардов документов. Например, модель Google Word2Vec обучается с использованием 3 миллионов слов и фраз.\n"
      ],
      "metadata": {
        "id": "iinQyXVGHGo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs \n",
        "import urllib.request \n",
        "import re \n",
        "import nltk \n",
        "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence') \n",
        "article = scrapped_data .read() \n",
        "parsed_article = bs.BeautifulSoup(article,'lxml') \n",
        "paragraphs = parsed_article.find_all('p') \n",
        "article_text = \"\" \n",
        "for p in paragraphs: \n",
        "  article_text += p.text\n"
      ],
      "metadata": {
        "id": "7BrO8HTWFJd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Во-первых, нам нужно преобразовать нашу статью в предложения. Мы используем утилиту nltk.sent_tokenize для преобразования нашей статьи в предложения. Для преобразования предложений в слова мы используем утилиту nltk.word_tokenize. На последнем этапе предварительной обработки мы удаляем из текста все стоп-слова. После того, как скрипт завершит свое выполнение, объект all_words содержит список всех слов в статье. Мы будем использовать этот список для создания нашей модели Word2Vec с библиотекой Gensim."
      ],
      "metadata": {
        "id": "WuUJGd88Idkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Cleaing the text \n",
        "processed_article = article_text.lower() \n",
        "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article ) \n",
        "processed_article = re.sub(r'\\s+', ' ', processed_article) \n",
        "# Preparing the dataset \n",
        "all_sentences = nltk.sent_tokenize(processed_article) \n",
        "all_words = [nltk.word_tokenize(sent) for sent in all_sentences] \n",
        "# Removing Stop Words \n",
        "from nltk.corpus import stopwords \n",
        "for i in range(len(all_words)): \n",
        "  all_words[i] = [w for w in all_words[i] \n",
        "                  if w not in stopwords.words('english')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou2MDL2XFvLH",
        "outputId": "c822c9bb-7c98-493d-fb1a-6468224e4052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Значение 2 для min_count указывает на включение в модель Word2Vec только тех слов, которые встречаются в корпусе как минимум дважды."
      ],
      "metadata": {
        "id": "7y0lE_WYJJbm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLqsb0yE2tW2"
      },
      "source": [
        "from gensim.models import Word2Vec \n",
        "word2vec = Word2Vec(all_words, min_count=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7js7jyg2tZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d7d42c-c8fe-457e-c3d8-8d12c03e5c79"
      },
      "source": [
        "vocabulary = word2vec.wv.key_to_index \n",
        "print(vocabulary)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ai': 0, 'intelligence': 1, 'artificial': 2, 'learning': 3, 'machine': 4, 'human': 5, 'problems': 6, 'networks': 7, 'many': 8, 'research': 9, 'used': 10, 'also': 11, 'knowledge': 12, 'search': 13, 'neural': 14, 'use': 15, 'symbolic': 16, 'researchers': 17, 'may': 18, 'logic': 19, 'general': 20, 'field': 21, 'systems': 22, 'machines': 23, 'computer': 24, 'problem': 25, 'would': 26, 'humans': 27, 'data': 28, 'reasoning': 29, 'algorithms': 30, 'mind': 31, 'applications': 32, 'solve': 33, 'tools': 34, 'intelligent': 35, 'goals': 36, 'could': 37, 'computing': 38, 'one': 39, 'specific': 40, 'system': 41, 'include': 42, 'example': 43, 'decision': 44, 'since': 45, 'developed': 46, 'two': 47, 'number': 48, 'optimization': 49, 'approaches': 50, 'ability': 51, 'program': 52, 'mathematical': 53, 'recognition': 54, 'risk': 55, 'however': 56, 'based': 57, 'world': 58, 'information': 59, 'including': 60, 'theory': 61, 'u': 62, 'difficult': 63, 'well': 64, 'others': 65, 'using': 66, 'deep': 67, 'first': 68, 'agent': 69, 'term': 70, 'even': 71, 'level': 72, 'language': 73, 'goal': 74, 'neurons': 75, 'algorithm': 76, 'known': 77, 'form': 78, 'input': 79, 'processing': 80, 'described': 81, 'inputs': 82, 'several': 83, 'make': 84, 'question': 85, 'widely': 86, 'sub': 87, 'time': 88, 'model': 89, 'robotics': 90, 'called': 91, 'solutions': 92, 'increase': 93, 'related': 94, 'rather': 95, 'methods': 96, 'whether': 97, 'humanity': 98, 'objects': 99, 'successful': 100, 'techniques': 101, 'behavior': 102, 'like': 103, 'particular': 104, 'fiction': 105, 'formal': 106, 'turing': 107, 'issue': 108, 'approach': 109, 'tasks': 110, 'perception': 111, 'commonsense': 112, 'facts': 113, 'states': 114, 'know': 115, 'classifiers': 116, 'considered': 117, 'examples': 118, 'things': 119, 'become': 120, 'google': 121, 'natural': 122, 'vision': 123, 'logics': 124, 'often': 125, 'inspired': 126, 'brain': 127, 'solving': 128, 'large': 129, 'software': 130, 'argues': 131, 'representation': 132, 'long': 133, 'patent': 134, 'philosophy': 135, 'processes': 136, 'beings': 137, 'ethics': 138, 'us': 139, 'programs': 140, 'statistical': 141, 'content': 142, 'patents': 143, 'bias': 144, 'future': 145, 'creating': 146, 'economics': 147, 'outputs': 148, 'science': 149, 'classification': 150, 'made': 151, 'simulate': 152, 'became': 153, 'spam': 154, 'new': 155, 'understanding': 156, 'thus': 157, 'g': 158, 'step': 159, 'r': 160, 'began': 161, 'layers': 162, 'making': 163, 'works': 164, 'computational': 165, 'among': 166, 'modern': 167, 'rights': 168, 'go': 169, 'planning': 170, 'capable': 171, 'argue': 172, 'technique': 173, 'jobs': 174, 'possible': 175, 'application': 176, 'technology': 177, 'popular': 178, 'simple': 179, 'people': 180, 'calculus': 181, 'russell': 182, 'speech': 183, 'laws': 184, 'easy': 185, 'space': 186, 'allow': 187, 'robots': 188, 'learn': 189, 'part': 190, 'soft': 191, 'far': 192, 'process': 193, 'advanced': 194, 'designed': 195, 'market': 196, 'simulated': 197, 'minsky': 198, 'another': 199, 'heuristics': 200, 'early': 201, 'different': 202, 'forms': 203, 'analyze': 204, 'logical': 205, 'sufficiently': 206, 'fields': 207, 'various': 208, 'choices': 209, 'analysis': 210, 'uses': 211, 'similar': 212, 'projects': 213, 'generation': 214, 'marvin': 215, 'multi': 216, 'lead': 217, 'due': 218, 'size': 219, 'reduced': 220, 'high': 221, 'highly': 222, 'solution': 223, 'guess': 224, 'industry': 225, 'accuracy': 226, 'included': 227, 'set': 228, 'categories': 229, 'domains': 230, 'antiquity': 231, 'person': 232, 'percent': 233, 'defined': 234, 'real': 235, 'events': 236, 'true': 237, 'capabilities': 238, 'common': 239, 'computers': 240, 'digital': 241, 'much': 242, 'work': 243, 'issues': 244, 'published': 245, 'classify': 246, 'still': 247, 'classifier': 248, 'able': 249, 'viewed': 250, 'especially': 251, 'function': 252, 'patterns': 253, 'founder': 254, 'k': 255, 'experience': 256, 'achieve': 257, 'ethical': 258, 'feel': 259, 'introduced': 260, 'text': 261, 'terms': 262, 'performance': 263, 'class': 264, 'equity': 265, 'e': 266, 'identify': 267, 'internet': 268, 'layer': 269, 'neuron': 270, 'traffic': 271, 'microsoft': 272, 'training': 273, 'together': 274, 'years': 275, 'smart': 276, 'self': 277, 'followed': 278, 'funding': 279, 'network': 280, 'definition': 281, 'previous': 282, 'devices': 283, 'recommendation': 284, 'prevent': 285, 'chaosgpt': 286, 'ontology': 287, 'concepts': 288, 'relations': 289, 'winter': 290, 'study': 291, 'life': 292, 'concern': 293, 'agents': 294, 'led': 295, 'facebook': 296, 'directly': 297, 'total': 298, 'computation': 299, 'reported': 300, 'properties': 301, 'typically': 302, 'ontologies': 303, 'principles': 304, 'created': 305, 'considers': 306, 'requires': 307, 'driving': 308, 'improve': 309, 'areas': 310, 'discovery': 311, 'philosophical': 312, 'superintelligence': 313, 'express': 314, 'statements': 315, 'breadth': 316, 'default': 317, 'bayesian': 318, 'identified': 319, 'image': 320, 'improved': 321, 'sense': 322, 'amazon': 323, 'philosophers': 324, 'need': 325, 'area': 326, 'suggested': 327, 'companies': 328, 'increased': 329, 'thinking': 330, 'legal': 331, 'longer': 332, 'gpt': 333, 'hard': 334, 'simon': 335, 'largest': 336, 'experts': 337, 'adopted': 338, 'commercial': 339, 'better': 340, 'connectionist': 341, 'governments': 342, 'sought': 343, 'critics': 344, 'emerging': 345, 'symbol': 346, 'failed': 347, 'risks': 348, 'proposed': 349, 'within': 350, 'demonstrated': 351, 'stephen': 352, 'asimov': 353, 'control': 354, 'middle': 355, 'word': 356, 'strategies': 357, 'reason': 358, 'without': 359, 'pattern': 360, 'philosopher': 361, 'determine': 362, 'norvig': 363, 'benchmarks': 364, 'web': 365, 'agree': 366, 'global': 367, 'algorithmic': 368, 'rarely': 369, 'playing': 370, 'consider': 371, 'produce': 372, 'narrow': 373, 'test': 374, 'finding': 375, 'late': 376, 'evolutionary': 377, 'generally': 378, 'fuzzy': 379, 'design': 380, 'bot': 381, 'champion': 382, 'translation': 383, 'show': 384, 'games': 385, 'engineering': 386, 'regression': 387, 'higher': 388, 'sources': 389, 'likely': 390, 'require': 391, 'around': 392, 'animal': 393, 'might': 394, 'ensure': 395, 'founded': 396, 'academic': 397, 'steps': 398, 'genetic': 399, 'friendly': 400, 'searching': 401, 'chess': 402, 'game': 403, 'move': 404, 'position': 405, 'straightforward': 406, 'superintelligent': 407, 'makes': 408, 'interaction': 409, 'trained': 410, 'effect': 411, 'development': 412, 'filed': 413, 'reach': 414, 'potential': 415, 'point': 416, 'matching': 417, 'central': 418, 'path': 419, 'actions': 420, 'moravec': 421, 'century': 422, 'st': 423, 'scientific': 424, 'idea': 425, 'morality': 426, 'begin': 427, 'match': 428, 'required': 429, 'truth': 430, 'functions': 431, 'statistics': 432, 'tend': 433, 'services': 434, 'subjective': 435, 'defendants': 436, 'activation': 437, 'classifies': 438, 'public': 439, 'success': 440, 'probability': 441, 'care': 442, 'programming': 443, 'n': 444, 'continuous': 445, 'gradient': 446, 'way': 447, 'swarm': 448, 'relationship': 449, 'researching': 450, 'manipulation': 451, 'emerged': 452, 'white': 453, 'automation': 454, 'languages': 455, 'frequently': 456, 'jurisdictions': 457, 'decades': 458, 'compas': 459, 'unfair': 460, 'prominence': 461, 'series': 462, 'presented': 463, 'gained': 464, 'intellectual': 465, 'simulating': 466, 'gofai': 467, 'create': 468, 'weapons': 469, 'misinformation': 470, 'second': 471, 'ways': 472, 'connections': 473, 'culture': 474, 'surveillance': 475, 'member': 476, 'necessary': 477, 'james': 478, 'provides': 479, 'benefit': 480, 'regulation': 481, 'done': 482, 'taking': 483, 'three': 484, 'worth': 485, 'databases': 486, 'herbert': 487, 'newell': 488, 'manyika': 489, 'physical': 490, 'proponents': 491, 'becomes': 492, 'countries': 493, 'period': 494, 'developing': 495, 'experienced': 496, 'collar': 497, 'waves': 498, 'upon': 499, 'cybernetics': 500, 'youtube': 501, 'learned': 502, 'netflix': 503, 'explored': 504, 'red': 505, 'competing': 506, 'computationalism': 507, 'scientists': 508, 'produced': 509, 'mistakes': 510, 'said': 511, 'body': 512, 'existential': 513, 'searle': 514, 'suffer': 515, 'april': 516, 'neats': 517, 'wide': 518, 'range': 519, 'explain': 520, 'provably': 521, 'stuart': 522, 'chatgpt': 523, 'assumption': 524, 'precisely': 525, 'consciousness': 526, 'cars': 527, 'alexa': 528, 'raised': 529, 'art': 530, 'musk': 531, 'arguments': 532, 'peter': 533, 'siri': 534, 'named': 535, 'openai': 536, 'attempts': 537, 'hypothetical': 538, 'beneficial': 539, 'attain': 540, 'resources': 541, 'transhumanism': 542, 'helping': 543, 'prominent': 544, 'altered': 545, 'proved': 546, 'act': 547, 'phenomenon': 548, 'hawking': 549, 'deduction': 550, 'economists': 551, 'dominated': 552, 'nuclear': 553, 'tweet': 554, 'cause': 555, 'engines': 556, 'alan': 557, 'c': 558, 'singularity': 559, 'technological': 560, 'appeared': 561, 'storytelling': 562, 'robot': 563, 'centuries': 564, 'institute': 565, 'mary': 566, 'shelley': 567, 'frankenstein': 568, 'shut': 569, 'karel': 570, 'apek': 571, 'impossible': 572, 'discussed': 573, 'away': 574, 'name': 575, 'attributed': 576, 'conscious': 577, 'moving': 578, 'sufficient': 579, 'result': 580, 'tree': 581, 'supply': 582, 'came': 583, 'blind': 584, 'random': 585, 'landscape': 586, 'top': 587, 'guesses': 588, 'ant': 589, 'order': 590, 'degree': 591, 'help': 592, 'handle': 593, 'situation': 594, 'belief': 595, 'devised': 596, 'dynamic': 597, 'filtering': 598, 'markov': 599, 'models': 600, 'measure': 601, 'valuable': 602, 'simplest': 603, 'divided': 604, 'types': 605, 'searches': 606, 'means': 607, 'algebra': 608, 'target': 609, 'occurrence': 610, 'appears': 611, 'sensors': 612, 'signals': 613, 'facial': 614, 'object': 615, 'visual': 616, 'affective': 617, 'virtual': 618, 'assistants': 619, 'programmed': 620, 'otherwise': 621, 'users': 622, 'existing': 623, 'actually': 624, 'successes': 625, 'sentiment': 626, 'hans': 627, 'individual': 628, 'cognitive': 629, 'architecture': 630, 'hopes': 631, 'believe': 632, 'features': 633, 'critical': 634, 'inference': 635, 'find': 636, 'diamond': 637, 'controllers': 638, 'therefore': 639, 'observations': 640, 'cases': 641, 'hardware': 642, 'includes': 643, 'mainstream': 644, 'autonomous': 645, 'apple': 646, 'face': 647, 'thousands': 648, 'deepfakes': 649, 'medical': 650, 'policy': 651, 'blue': 652, 'beat': 653, 'jeopardy': 654, 'ibm': 655, 'becoming': 656, 'superhuman': 657, 'deepmind': 658, 'hours': 659, 'decisions': 660, 'detector': 661, 'images': 662, 'inappropriate': 663, 'security': 664, 'professor': 665, 'installed': 666, 'cities': 667, 'back': 668, 'rnn': 669, 'reduce': 670, 'technologies': 671, 'certain': 672, 'observation': 673, 'classified': 674, 'nearest': 675, 'neighbor': 676, 'svm': 677, 'naive': 678, 'bayes': 679, 'scalability': 680, 'depends': 681, 'perform': 682, 'extremely': 683, 'weighted': 684, 'convolutional': 685, 'fire': 686, 'wire': 687, 'spectrum': 688, 'descent': 689, 'competitive': 690, 'feedforward': 691, 'signal': 692, 'recurrent': 693, 'short': 694, 'perceptrons': 695, 'relevant': 696, 'important': 697, 'useful': 698, 'structure': 699, 'translate': 700, 'traits': 701, 'brooks': 702, 'focused': 703, 'survive': 704, 'interest': 705, 'david': 706, 'pigeons': 707, 'exactly': 708, 'define': 709, 'verifiable': 710, 'mathematics': 711, 'although': 712, 'access': 713, 'must': 714, 'hungry': 715, 'started': 716, 'according': 717, 'usage': 718, 'survey': 719, 'incorporated': 720, 'numerous': 721, 'concerned': 722, 'fully': 723, 'matter': 724, 'current': 725, 'involves': 726, 'observe': 727, 'agi': 728, 'rodney': 729, 'john': 730, 'mccarthy': 731, 'remaining': 732, 'theorems': 733, 'funded': 734, 'established': 735, 'eventually': 736, 'predicted': 737, 'twenty': 738, 'man': 739, 'agreed': 740, 'writing': 741, 'substantially': 742, 'recognize': 743, 'difficulty': 744, 'british': 745, 'simulation': 746, 'next': 747, 'later': 748, 'history': 749, 'revived': 750, 'discussion': 751, 'billion': 752, 'view': 753, 'japan': 754, 'fifth': 755, 'beginning': 756, 'lisp': 757, 'defines': 758, 'institutions': 759, 'expect': 760, 'answering': 761, 'received': 762, 'support': 763, 'fundamental': 764, 'concept': 765, 'j': 766, 'finds': 767, 'inventions': 768, 'supervised': 769, 'main': 770, 'something': 771, 'belongs': 772, 'four': 773, 'change': 774, 'learners': 775, 'good': 776, 'responses': 777, 'ones': 778, 'strategy': 779, 'applied': 780, 'assess': 781, 'complexity': 782, 'sample': 783, 'nlp': 784, 'allows': 785, 'understand': 786, 'powerful': 787, 'texts': 788, 'papers': 789, 'retrieval': 790, 'dick': 791, 'enormous': 792, 'intelligently': 793, 'measures': 794, 'puzzles': 795, 'machinery': 796, 'deductions': 797, 'uncertain': 798, 'incomplete': 799, 'explosion': 800, 'exponentially': 801, 'thinks': 802, 'wrote': 803, 'fast': 804, 'questions': 805, 'personal': 806, 'changing': 807, 'exists': 808, 'interpret': 809, 'attempt': 810, 'domain': 811, 'average': 812, 'knows': 813, 'represented': 814, 'description': 815, 'represent': 816, 'refer': 817, 'assume': 818, 'told': 819, 'textbooks': 820}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzt4sYd52tcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f0c251-eb07-4ae9-c398-157601be7279"
      },
      "source": [
        "v1 = word2vec.wv['artificial']\n",
        "v1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.60073338e-03,  5.08260261e-03, -5.05369715e-03, -1.19461026e-03,\n",
              "        7.02408003e-03,  1.75912608e-03, -2.59982119e-03,  1.06169907e-02,\n",
              "       -1.11749945e-02,  4.65675117e-03, -7.50510907e-03, -7.01052137e-03,\n",
              "        8.05803854e-03,  2.96750921e-03,  7.74817262e-03, -7.71344220e-03,\n",
              "        6.00213325e-03,  6.53982535e-03, -9.62967146e-03, -1.19432686e-02,\n",
              "       -5.28674945e-03, -3.40612722e-03, -3.16013675e-03, -1.07988175e-02,\n",
              "        6.45832065e-03, -3.98814818e-03,  4.86717559e-03,  2.31748703e-03,\n",
              "       -8.79074819e-03,  4.68504196e-03,  1.07759265e-02, -5.18562971e-03,\n",
              "       -5.22886589e-03, -4.26600734e-03, -1.11535434e-02,  2.53374968e-03,\n",
              "       -1.65568665e-04, -7.47654471e-04, -1.11759116e-03, -8.52265581e-03,\n",
              "       -6.12793630e-03, -9.06595727e-04, -1.25828164e-03,  5.86924329e-03,\n",
              "        5.89350192e-03,  1.82834442e-03, -5.02599054e-04, -2.67082779e-03,\n",
              "       -1.57851016e-03,  7.01579324e-04,  3.39879980e-03, -6.07468095e-03,\n",
              "       -8.02578218e-03, -8.07783008e-03, -1.12150339e-02, -3.86543525e-03,\n",
              "        3.01567867e-04, -3.90856527e-03, -1.04889534e-02, -2.17267708e-03,\n",
              "        5.49940346e-03, -2.39522057e-03,  6.88612647e-03, -6.29338669e-04,\n",
              "       -1.22205084e-02,  1.11329779e-02,  9.22660902e-03,  8.17855820e-03,\n",
              "       -1.20903272e-02,  9.06547066e-03,  2.11845827e-03,  6.22504996e-03,\n",
              "        7.20612798e-03,  2.77887244e-04, -9.60480902e-05,  1.09138526e-02,\n",
              "        9.61243268e-03,  2.93385633e-03, -5.97045245e-03,  2.13050796e-03,\n",
              "       -8.50416603e-04, -9.91594978e-03, -1.17023522e-02,  6.69752760e-03,\n",
              "        1.08511501e-03, -5.65685099e-03, -4.57906118e-03, -2.41586799e-03,\n",
              "        1.21150855e-02,  2.86833005e-04,  1.35815458e-03,  7.02131679e-03,\n",
              "        9.63500049e-03, -3.79795977e-03,  1.31250713e-02,  8.95261206e-03,\n",
              "        7.66430609e-03, -2.41634995e-03,  1.01535898e-02, -7.47826090e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_words = word2vec.wv.most_similar('intelligence')\n",
        "sim_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS2FQX8cGqa4",
        "outputId": "3d2f30d7-f71c-4e6a-fc91-92562ebba8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('smart', 0.4090029001235962),\n",
              " ('may', 0.3627232015132904),\n",
              " ('humans', 0.3279481530189514),\n",
              " ('ai', 0.3214792013168335),\n",
              " ('systems', 0.31423211097717285),\n",
              " ('methods', 0.3131225109100342),\n",
              " ('ability', 0.30731719732284546),\n",
              " ('machines', 0.30406704545021057),\n",
              " ('search', 0.2984282076358795),\n",
              " ('economics', 0.2977701425552368)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFV3mwv32tx6"
      },
      "source": [
        "## Распознание спама\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohk86_AkEpHO"
      },
      "source": [
        "#Загружаем данные и разархивируем"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmBl1kYSgYKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bbb479-511c-414f-a338-bc58c81e93c1"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-17 10:10:02--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203415 (199K) [application/x-httpd-php]\n",
            "Saving to: ‘smsspamcollection.zip’\n",
            "\n",
            "smsspamcollection.z 100%[===================>] 198.65K   734KB/s    in 0.3s    \n",
            "\n",
            "2023-04-17 10:10:03 (734 KB/s) - ‘smsspamcollection.zip’ saved [203415/203415]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7R0VF0hLi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbf4fb2-a149-40d2-cc81-fc4c546b56d1"
      },
      "source": [
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  smsspamcollection.zip\n",
            "  inflating: SMSSpamCollection       \n",
            "  inflating: readme                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пакет torch содержит структуры данных для многомерных тензоров и определяет математические операции над этими тензорами. Кроме того, он предоставляет множество утилит для эффективной сериализации тензоров и произвольных типов, а также другие полезные утилиты."
      ],
      "metadata": {
        "id": "XHlKIi0ESufm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjo8ESvlhcPo"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3JFt1_heVf"
      },
      "source": [
        "df = pd.read_table('SMSSpamCollection',sep='\\t',header=None, names=['label','sms_message'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ZHy_yREyZL"
      },
      "source": [
        "#Данные "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x52h9vRChx6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a9acd223-e4ef-4fa5-ec47-3accb9c4d137"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b36d5125-1c96-4c48-8490-614a364c9777\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b36d5125-1c96-4c48-8490-614a364c9777')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b36d5125-1c96-4c48-8490-614a364c9777 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b36d5125-1c96-4c48-8490-614a364c9777');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOL8ZOTj7nLk"
      },
      "source": [
        "### Наивный Байесовский классификатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XPxVNwcE0VQ"
      },
      "source": [
        "#заменяем целевую переменную"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWkV2v6vh9_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7f80e137-ffc2-4409-fc03-329f8301b77d"
      },
      "source": [
        "df['label'] = df.label.map({'ham':0,'spam':1})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb0e1c62-3ae1-48a6-8711-79be16f8152d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb0e1c62-3ae1-48a6-8711-79be16f8152d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb0e1c62-3ae1-48a6-8711-79be16f8152d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb0e1c62-3ae1-48a6-8711-79be16f8152d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_LGvC_eiO2R"
      },
      "source": [
        "#Делим на трейновую и тестовую выборку\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FXkBq1liubV"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGG3yn_ni4Fb"
      },
      "source": [
        "#Считаем количество слов в предложениях\n",
        "#получим матрицу размером (количество предложений Х размер словаря)\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "training_data = count_vector.fit_transform(X_train).toarray().astype('float')\n",
        "testing_data = count_vector.transform(X_test).toarray().astype('float')\n",
        "\n",
        "# переводим в тензоры\n",
        "train_tensor = torch.tensor(training_data)\n",
        "test_tensor = torch.tensor(testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-8u-n3JFMUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0051c25-bbe5-463a-a2fe-8e769681e3bf"
      },
      "source": [
        "# размер трейновой выборки\n",
        "training_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4179, 7456)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i7YMz6B--zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbdeaa1-cfab-40a1-834a-daf989406bb3"
      },
      "source": [
        "# всего слов в предложениях\n",
        "train_tensor.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(59839., dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv_Ayn9y-lSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f45e2f8-65ff-4054-8b39-0588aa8ae1b2"
      },
      "source": [
        "# тензор с предложениями класса spam\n",
        "spam_train_tensor = train_tensor[(y_train == 1).values]\n",
        "\n",
        "# тензор с предложениями класса not_spam\n",
        "not_spam_train_tensor = train_tensor[(y_train == 0).values]\n",
        "spam_train_tensor.shape, not_spam_train_tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([562, 7456]), torch.Size([3617, 7456]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeG_Gl8O_7D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ea2616-cfcc-4926-dd64-2645994ac983"
      },
      "source": [
        "\n",
        "#Вероятность слова при условии что предложение спам\n",
        "p_w_spam = (spam_train_tensor.sum(axis=0)) / (spam_train_tensor.sum())\n",
        "\n",
        "#Вероятность слова при условии что предложение не спам\n",
        "p_w_not_spam = (not_spam_train_tensor.sum(axis=0)) / (not_spam_train_tensor.sum())\n",
        "\n",
        "p_w_spam, p_w_not_spam\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0004, 0.0018, 0.0002,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        dtype=torch.float64),\n",
              " tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1413e-05, 2.1413e-05,\n",
              "         2.1413e-05], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip3ppOacAFDb"
      },
      "source": [
        "# вероятность, что любое сообщение спам\n",
        "p_spam = (y_train == 1).values.sum() / len(y_train)\n",
        "\n",
        "# вероятность, что любое сообщение не спам\n",
        "p_not_spam = (y_train == 0).values.sum() / len(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bueUTH1vQki-"
      },
      "source": [
        "#проверим на одном семпле\n",
        "test_sample = test_tensor[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWL7Ey59NIme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f938a2-53c8-423f-a2b2-1eaa23e51731"
      },
      "source": [
        "# посчитает значение за спам \n",
        "# пляски с прибавлением числа e и вычитания единицы используются для того,\n",
        "# что бы небыло минус бесконечности после взятия логарифма и суммировались неотрицательные значения\n",
        "np.log(p_spam+2.71828182846)-1 + (((test_sample*p_w_spam)+2.71828182846).log()-1).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0535, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcnBJX-uNIto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a83edae-129b-49b7-e6b6-52b67d6eb5ec"
      },
      "source": [
        "#посчитаем значение против спама\n",
        "np.log(p_not_spam+2.71828182846)-1 + (((test_sample*p_w_not_spam)+2.71828182846).log()-1).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2841, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLaVXqtVYNEx"
      },
      "source": [
        "# видно что значение против спама больше, чем значение за спам \n",
        "# соответственно значение не спам"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOBlAOR2SXUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa29791d-36d3-4999-9acf-edf5b0dcf65c"
      },
      "source": [
        "#посчитаем для всей тестовой выборки\n",
        "\n",
        "#размер тестовой выборки\n",
        "test_tensor.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1393, 7456])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu1eCJFxA_yw"
      },
      "source": [
        "#посчитаем предсказания как сравнение величинв за спам и против спама\n",
        "y_pred = (np.log(p_spam+2.71828182846)-1 + (((test_tensor*p_w_spam)+2.71828182846).log()-1).sum(dim=1)) >= \\\n",
        " np.log(p_not_spam+2.71828182846)-1 + (((test_tensor*p_w_not_spam)+2.71828182846).log()-1).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOIICObeUCRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4857b89b-44ed-41c0-c781-afc74d51e8b2"
      },
      "source": [
        "# предсказанные значения\n",
        "y_pred.int()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XboU8FR8T_2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a9a375-e69a-42f5-ae40-bd05443fb391"
      },
      "source": [
        "#истиные значение\n",
        "y_test.to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOya3FpTy-O"
      },
      "source": [
        "#сравним реальные метки с предсказанными\n",
        "test = (y_pred == torch.tensor(y_test.to_numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUoRgb7UXZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e479d3-a730-4833-e707-9a4815fe4e60"
      },
      "source": [
        "#посчитаем точность модели как отношение количество совпадений к размеру выборки  \n",
        "test.sum().item()/test.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8671931083991385"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sJWduFqEPnM"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# обучить классификатор\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(train_tensor, y_train)\n",
        "predicted = classifier.predict(test_tensor) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbNwJ3HAXNzN",
        "outputId": "b9589a50-6331-4bf5-fac7-2a931a4a8fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1393,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IanPQai8XR1l",
        "outputId": "b68b9276-ad37-482e-a65e-49b5ced654f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1393,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим, количество ошибок довольно сбалансировано между законным и спамом: 5 легитимных сообщения классифицируются как спам, а 11 спам-сообщений классифицируются как легитимные. В целом, это очень хорошие результаты для нашего простого классификатора."
      ],
      "metadata": {
        "id": "N4-iKEijYAUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        " \n",
        "print(confusion_matrix(y_test, predicted)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWYHajpVhls",
        "outputId": "bf94e239-ac28-4e67-e5f4-a8d432fccba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1203    5]\n",
            " [  11  174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asRvgxZPXkT9",
        "outputId": "fc89627f-ffbd-4b2a-e732-38efbe7d351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9885139985642498"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qncCcPbtotw",
        "outputId": "7af51dc1-24d6-4331-ddf9-70dd2c70ff1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1208\n",
            "           1       0.97      0.94      0.96       185\n",
            "\n",
            "    accuracy                           0.99      1393\n",
            "   macro avg       0.98      0.97      0.97      1393\n",
            "weighted avg       0.99      0.99      0.99      1393\n",
            "\n"
          ]
        }
      ]
    }
  ]
}